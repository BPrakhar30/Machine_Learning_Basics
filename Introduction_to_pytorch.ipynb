{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uc0IXcXq7pEE"
   },
   "source": [
    "## Recitation 1 : 24788 - Introduction to Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5enyRdM5to8"
   },
   "source": [
    "## Introduction to Pytorch \n",
    "\n",
    "Pytorch is an open source deep learning from Facebook AI. It provides great flexibility for research and is a very popular tool among deep learning practioners. \n",
    "\n",
    "#### Installation instruction for pytorch \n",
    "https://pytorch.org\n",
    "\n",
    "\n",
    "#### What is a tensor \n",
    "1. Tensors can be thought of as multidimensional arrays\n",
    "2. You can run tensor operations on a GPU or a CPU  \n",
    "\n",
    "\n",
    "https://machinelearningmastery.com/introduction-to-tensors-for-machine-learning/\n",
    "\n",
    "#### Note\n",
    "The content of this recitation has been inspired from from pytorch's own tutorials on tensors and its operations and 11785 - Introduction to Deep Learning (CMU) - https://deeplearning.cs.cmu.edu/S22/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 20 16:04:22 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 32%   58C    P2    52W / 250W |   4569MiB / 11177MiB |     26%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1312      G   /usr/lib/xorg/Xorg                 18MiB |\r\n",
      "|    0   N/A  N/A      1365      G   /usr/bin/gnome-shell               69MiB |\r\n",
      "|    0   N/A  N/A      1918      G   /usr/lib/xorg/Xorg                203MiB |\r\n",
      "|    0   N/A  N/A      2037      G   /usr/bin/gnome-shell               28MiB |\r\n",
      "|    0   N/A  N/A     10006      G   ...AAAAAAAA== --shared-files        4MiB |\r\n",
      "|    0   N/A  N/A     10620      G   ...RendererForSitePerProcess       27MiB |\r\n",
      "|    0   N/A  N/A     15680      C   ...envs/pdevae/bin/python3.7      751MiB |\r\n",
      "|    0   N/A  N/A     16584      C   ...envs/pdevae/bin/python3.7     3445MiB |\r\n",
      "|    0   N/A  N/A     27633      G   /usr/bin/anydesk                   12MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1641077334629,
     "user": {
      "displayName": "Lavanya Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPZ-gFUKBYLSyxzBmt3TzRRafineDUBkmyCxat=s64",
      "userId": "00183741301248640044"
     },
     "user_tz": 300
    },
    "id": "TFGEMbH34Lxy"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Wed_Oct_23_19:24:38_PDT_2019\r\n",
      "Cuda compilation tools, release 10.2, V10.2.89\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1641077379400,
     "user": {
      "displayName": "Lavanya Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPZ-gFUKBYLSyxzBmt3TzRRafineDUBkmyCxat=s64",
      "userId": "00183741301248640044"
     },
     "user_tz": 300
    },
    "id": "Uvcs92AiAac7",
    "outputId": "fb4737c9-6e32-4725-a327-3b21b61562d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check to see if your system has gpu\n",
    "device = torch.cuda.is_available()\n",
    "print(device) # prints True if gpu is available, else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Z6Qy7hH2iEr"
   },
   "source": [
    "### Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1641077501065,
     "user": {
      "displayName": "Lavanya Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPZ-gFUKBYLSyxzBmt3TzRRafineDUBkmyCxat=s64",
      "userId": "00183741301248640044"
     },
     "user_tz": 300
    },
    "id": "Yqgicxmu2Z5X",
    "outputId": "d94f9e7f-eefc-4e7e-d02b-81372fbe1ab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[0.6960, 0.7982, 0.8229, 0.5514],\n",
      "        [0.2032, 0.1160, 0.4835, 0.5527],\n",
      "        [0.9358, 0.6476, 0.7183, 0.5918]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.zeros(size=(4,3))  # creates a tensor of Zeros with the given shape     \n",
    "t2 = torch.ones((4,4))   # creates a tensor of ones with  given shape            \n",
    "t3 = torch.rand(size=(3,4))   #  creates a tensor of the given shape by uniformly sampling between 0 and 1              \n",
    "\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuUqIXifsbc2"
   },
   "source": [
    "#### Tensor conversion and creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1641077576007,
     "user": {
      "displayName": "Lavanya Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPZ-gFUKBYLSyxzBmt3TzRRafineDUBkmyCxat=s64",
      "userId": "00183741301248640044"
     },
     "user_tz": 300
    },
    "id": "bDQvfUfc4YFl",
    "outputId": "74fd6e36-24ee-4575-f304-e612824c57d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: tensor([1, 2, 3, 4])\n",
      "t2: tensor([1, 2, 3, 4])\n",
      "t3: tensor([1, 2, 3, 4])\n",
      "t4: tensor([1, 2, 3, 4])\n",
      "a1: [1 2 3 4]\n",
      "t1 - data type: tensor([1, 2, 3, 4]) torch.int64\n",
      "f1 - data type: tensor([1., 2., 3., 4.]) torch.float32\n",
      "d1 - data type: tensor([1., 2., 3., 4.], dtype=torch.float64) torch.float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Pytorch can create a tensor by directly infering the type of data\n",
    "data_list =  [1,2,3,4]\n",
    "t1 = torch.tensor(data_list)    # Creating Tensor from a list \n",
    "\n",
    "data_arr =  np.array([1,2,3,4]) # Creating a tensor from numpy array\n",
    "t2 = torch.tensor(data_arr)    \n",
    "\n",
    "t3 = torch.from_numpy(data_arr) # Creating a tensor from numpy array\n",
    "\n",
    "t4 = t3.clone()                 # copy from existing torch tensor\n",
    "\n",
    "print(\"t1:\",t1)\n",
    "print(\"t2:\",t2)\n",
    "print(\"t3:\",t3)\n",
    "print(\"t4:\",t4)\n",
    "\n",
    "\n",
    "## We can also convert the tensor back to numpy array\n",
    "\n",
    "a1 = t2.numpy()\n",
    "print(\"a1:\",a1)\n",
    "\n",
    "\n",
    "## We can also convert the data types of the tensor \n",
    "f1 =  t1.float()\n",
    "\n",
    "d1 = t1.double()\n",
    "\n",
    "print(\"t1 - data type:\", t1, t1.dtype)\n",
    "print(\"f1 - data type:\", f1, f1.dtype)\n",
    "print(\"d1 - data type:\", d1, d1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6., 8.], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 + f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_cuda = d1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15680/3325294020.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md1_cuda\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "d1_cuda + d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbzEsytsfouT"
   },
   "source": [
    "More information on Tensor Conversion : (https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html)\n",
    "\n",
    "More information on Tensor datatypes: (https://pytorch.org/docs/stable/tensors.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vgo3dkKT6lky"
   },
   "source": [
    "\n",
    "### Tensor indexing & Slicing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1641077829203,
     "user": {
      "displayName": "Lavanya Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPZ-gFUKBYLSyxzBmt3TzRRafineDUBkmyCxat=s64",
      "userId": "00183741301248640044"
     },
     "user_tz": 300
    },
    "id": "7vlpFvSH6sSQ",
    "outputId": "ab6af843-9f12-49db-8198-18889c2fe8d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor t  tensor([[0.8350, 0.5333, 0.8385],\n",
      "        [0.6421, 0.5796, 0.3290],\n",
      "        [0.3277, 0.6140, 0.0450],\n",
      "        [0.0598, 0.6340, 0.1585]])\n",
      "Tensor shape torch.Size([4, 3])\n",
      "tensor(0.8350)\n",
      "tensor(0.1585)\n",
      "tensor([0.8350, 0.5333, 0.8385])\n",
      "tensor([[0.8350, 0.5333, 0.8385],\n",
      "        [0.6421, 0.5796, 0.3290]])\n",
      "tensor([0.8385, 0.3290, 0.0450, 0.1585])\n"
     ]
    }
   ],
   "source": [
    "# Indexing in tensors is similar to numpy array\n",
    "t = torch.rand(size=(4,3))\n",
    "\n",
    "print(\"Tensor t \",t)\n",
    "print(\"Tensor shape\", t.shape)\n",
    "\n",
    "### Accessing the elements in the the tensor is similar to numpy \n",
    "\n",
    "print(t[0,0])\n",
    "print(t[3,2])\n",
    "\n",
    "## Slicing is also similar to numpy \n",
    "\n",
    "print(t[0])\n",
    "print(t[:2])\n",
    "print(t[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSN_4hUCvoT7"
   },
   "source": [
    "### Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1641078096328,
     "user": {
      "displayName": "Lavanya Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPZ-gFUKBYLSyxzBmt3TzRRafineDUBkmyCxat=s64",
      "userId": "00183741301248640044"
     },
     "user_tz": 300
    },
    "id": "UJhvVufa9wxu",
    "outputId": "0b108118-1ed5-49e7-fa0c-f56e661c7719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7764, 0.3575, 0.9771, 0.6942],\n",
      "        [0.9241, 0.2583, 0.9544, 0.7713],\n",
      "        [0.1639, 0.3513, 0.6001, 0.5070]])\n",
      "torch.Size([3, 4])\n",
      "tensor([0.7764, 0.3575, 0.9771, 0.6942, 0.9241, 0.2583, 0.9544, 0.7713, 0.1639,\n",
      "        0.3513, 0.6001, 0.5070])\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(size=(3,4)) \n",
    "print(t) \n",
    "print(t.shape)               \n",
    "print(t.flatten())\n",
    "print(t.flatten().shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1641078456955,
     "user": {
      "displayName": "Lavanya Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPZ-gFUKBYLSyxzBmt3TzRRafineDUBkmyCxat=s64",
      "userId": "00183741301248640044"
     },
     "user_tz": 300
    },
    "id": "BFBm16dy_oml",
    "outputId": "58fb06d0-0a73-47af-f2c2-6fe7884ba734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal tensor shape:  torch.Size([3, 4])\n",
      "tensor([[0.7764, 0.3575, 0.9771, 0.6942, 0.9241, 0.2583],\n",
      "        [0.9544, 0.7713, 0.1639, 0.3513, 0.6001, 0.5070]]) torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "print('Orginal tensor shape: ', t.shape)\n",
    "t_re = t.reshape((2,6))\n",
    "print(t_re, t_re.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using View operation\n",
    "\n",
    "The view operation may not work in all cases, you may check the below link to know more about the differences\n",
    "https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal tensor shape:  torch.Size([3, 4])\n",
      "tensor([[0.7764, 0.3575, 0.9771, 0.6942, 0.9241, 0.2583],\n",
      "        [0.9544, 0.7713, 0.1639, 0.3513, 0.6001, 0.5070]]) torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "print('Orginal tensor shape: ', t.shape)\n",
    "t_v = t.view((2,6))\n",
    "print(t_v, t_v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the transpose operation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal tensor shape:  torch.Size([3, 4])\n",
      "tensor([[0.7764, 0.9241, 0.1639],\n",
      "        [0.3575, 0.2583, 0.3513],\n",
      "        [0.9771, 0.9544, 0.6001],\n",
      "        [0.6942, 0.7713, 0.5070]]) torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print('Orginal tensor shape: ', t.shape)\n",
    "t_t = t.transpose(0,1)\n",
    "print(t_t, t_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JLiewszwAwe"
   },
   "source": [
    "### Squeeze and Unsqueeze\n",
    "Squeeze and unsqueeze are especially useful when you want to add a dimension to a tensor. You may have to use them in coding convnets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal tensor shape:  torch.Size([3, 4])\n",
      "tensor([[[0.7764, 0.3575, 0.9771, 0.6942],\n",
      "         [0.9241, 0.2583, 0.9544, 0.7713],\n",
      "         [0.1639, 0.3513, 0.6001, 0.5070]]]) torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "#Unsqueeze\n",
    "\n",
    "print('Orginal tensor shape: ', t.shape)\n",
    "t_u = t.unsqueeze(dim = 0)\n",
    "print(t_u, t_u.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsqueeze tensor shape:  torch.Size([1, 3, 4])\n",
      "tensor([[0.7764, 0.3575, 0.9771, 0.6942],\n",
      "        [0.9241, 0.2583, 0.9544, 0.7713],\n",
      "        [0.1639, 0.3513, 0.6001, 0.5070]]) torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Squeeze\n",
    "\n",
    "print('Unsqueeze tensor shape: ', t_u.shape)\n",
    "t_s = t_u.squeeze(dim = 0)\n",
    "print(t_s, t_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLQwsolqxofG"
   },
   "source": [
    "### Permute Tensor\n",
    "\n",
    "Permute is especially useful when you have multideimensional array and can be used when we are required to swap axes in the tensors.\n",
    "\n",
    "For more information on permute, transpose, view, reshape : https://jdhao.github.io/2019/07/10/pytorch_view_reshape_transpose_permute/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1641078779551,
     "user": {
      "displayName": "Lavanya Gupta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPZ-gFUKBYLSyxzBmt3TzRRafineDUBkmyCxat=s64",
      "userId": "00183741301248640044"
     },
     "user_tz": 300
    },
    "id": "b-xquTpxtr8A",
    "outputId": "bd8f4975-3277-484a-92a0-af5e7c867886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape torch.Size([3, 4, 5])\n",
      "tensor([[[0.0186, 0.4665, 0.7608, 0.7620, 0.6668],\n",
      "         [0.5883, 0.1197, 0.1325, 0.4239, 0.1412],\n",
      "         [0.3235, 0.8802, 0.9862, 0.6877, 0.7067],\n",
      "         [0.0244, 0.0752, 0.3690, 0.6431, 0.9526]],\n",
      "\n",
      "        [[0.3555, 0.1257, 0.5786, 0.1062, 0.7484],\n",
      "         [0.6332, 0.8669, 0.3057, 0.5379, 0.1050],\n",
      "         [0.5895, 0.9318, 0.4647, 0.8507, 0.4045],\n",
      "         [0.0160, 0.2488, 0.5062, 0.3757, 0.4753]],\n",
      "\n",
      "        [[0.9061, 0.6909, 0.0712, 0.9085, 0.5604],\n",
      "         [0.5611, 0.4636, 0.0587, 0.6144, 0.6807],\n",
      "         [0.7668, 0.1375, 0.3162, 0.9746, 0.9654],\n",
      "         [0.5562, 0.0900, 0.8455, 0.6676, 0.7922]]])\n",
      "Permute tensor shape: torch.Size([4, 3, 5])\n",
      "tensor([[[0.0186, 0.4665, 0.7608, 0.7620, 0.6668],\n",
      "         [0.3555, 0.1257, 0.5786, 0.1062, 0.7484],\n",
      "         [0.9061, 0.6909, 0.0712, 0.9085, 0.5604]],\n",
      "\n",
      "        [[0.5883, 0.1197, 0.1325, 0.4239, 0.1412],\n",
      "         [0.6332, 0.8669, 0.3057, 0.5379, 0.1050],\n",
      "         [0.5611, 0.4636, 0.0587, 0.6144, 0.6807]],\n",
      "\n",
      "        [[0.3235, 0.8802, 0.9862, 0.6877, 0.7067],\n",
      "         [0.5895, 0.9318, 0.4647, 0.8507, 0.4045],\n",
      "         [0.7668, 0.1375, 0.3162, 0.9746, 0.9654]],\n",
      "\n",
      "        [[0.0244, 0.0752, 0.3690, 0.6431, 0.9526],\n",
      "         [0.0160, 0.2488, 0.5062, 0.3757, 0.4753],\n",
      "         [0.5562, 0.0900, 0.8455, 0.6676, 0.7922]]])\n"
     ]
    }
   ],
   "source": [
    "t_p = torch.rand(size = (3,4,5))\n",
    "\n",
    "print(\"Original tensor shape\",t_p.shape)\n",
    "print(t_p)\n",
    "\n",
    "print(\"Permute tensor shape:\", t_p.permute(1,0,2).shape)\n",
    "print(t_p.permute(1,0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ040S1mx4Bq"
   },
   "source": [
    "### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wUnPorUTkTH2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 1: tensor([[0.6312, 0.2007, 0.9081, 0.1016],\n",
      "        [0.8234, 0.1749, 0.9035, 0.2749],\n",
      "        [0.0488, 0.9051, 0.8055, 0.5865]])\n",
      "Tensor 2: tensor([[0.6168, 0.6756],\n",
      "        [0.4752, 0.1926],\n",
      "        [0.2090, 0.4825]])\n",
      "Concatenating two tensors along axis 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Got 4 and 2 in dimension 1 (The offending index is 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15680/1235964320.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Concatenating two tensors along axis 0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'New Shape: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## Row concatenation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Got 4 and 2 in dimension 1 (The offending index is 1)"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(size=(3,4))\n",
    "t2 = torch.rand(size=(3,4))\n",
    "\n",
    "print('Tensor 1:', t1)\n",
    "print('Tensor 2:', t2)\n",
    "\n",
    "print('Concatenating two tensors along axis 0')\n",
    "print(torch.cat([t1,t2],dim=0))\n",
    "print('New Shape: ', torch.cat([t1,t2],dim=0).shape) ## Row concatenation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSdHu7Mex9W6"
   },
   "source": [
    "### Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oruTiMZ8XQmJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 1 shape: torch.Size([3, 4])\n",
      "tensor([[0.0728, 0.8283, 0.9617, 0.5129],\n",
      "        [0.6253, 0.4481, 0.3212, 0.9238],\n",
      "        [0.6694, 0.6927, 0.7659, 0.4304]])\n",
      "Tensor 2 shape: torch.Size([3, 4])\n",
      "tensor([[0.2309, 0.8462, 0.1810, 0.6019],\n",
      "        [0.5666, 0.4586, 0.2713, 0.5802],\n",
      "        [0.5136, 0.5027, 0.9454, 0.5232]])\n",
      "tensor([[[0.0728, 0.8283, 0.9617, 0.5129],\n",
      "         [0.6253, 0.4481, 0.3212, 0.9238],\n",
      "         [0.6694, 0.6927, 0.7659, 0.4304]],\n",
      "\n",
      "        [[0.2309, 0.8462, 0.1810, 0.6019],\n",
      "         [0.5666, 0.4586, 0.2713, 0.5802],\n",
      "         [0.5136, 0.5027, 0.9454, 0.5232]]])\n",
      "New Shape: torch.Size([2, 3, 4]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(size=(3,4)) \n",
    "t2 = torch.rand(size=(3,4))\n",
    "\n",
    "print(\"Tensor 1 shape:\", t1.shape)\n",
    "print(t1)\n",
    "\n",
    "print(\"Tensor 2 shape:\", t2.shape)\n",
    "print(t2)\n",
    "\n",
    "print(torch.stack([t1,t2],dim=0)) #(3, 4) --> (1, 3, 4) --> (N, 3, 4) # stacks along the dimension to insert\n",
    "print(\"New Shape:\", torch.stack([t1,t2],dim=0).shape, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l49umlqay-Zd"
   },
   "source": [
    "### Computational operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor addition, multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HHks6PQ6MZxn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 1 tensor([[0.6054, 0.7673, 0.7317, 0.2100],\n",
      "        [0.7466, 0.1533, 0.1374, 0.0058],\n",
      "        [0.6464, 0.9646, 0.1740, 0.3705]])\n",
      "Tensor 2 tensor([[0.4959, 0.1798, 0.1164, 0.1563],\n",
      "        [0.7469, 0.8262, 0.7221, 0.4554],\n",
      "        [0.7212, 0.4184, 0.7196, 0.4577]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(size = (3,4))\n",
    "t2 = torch.rand(size = (3,4))\n",
    "\n",
    "print(\"Tensor 1\", t1)\n",
    "print(\"Tensor 2\", t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FvPDrbatMrfp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1+t2\n",
      "tensor([[1.1013, 0.9470, 0.8481, 0.3663],\n",
      "        [1.4935, 0.9795, 0.8595, 0.4612],\n",
      "        [1.3675, 1.3830, 0.8936, 0.8282]])\n"
     ]
    }
   ],
   "source": [
    "### Adding two tensors\n",
    "print('t1+t2')\n",
    "print(t1+t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "kq8kKFbD1b0P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element wise multiplication t1*t2\n",
      "tensor([[0.3002, 0.1379, 0.0852, 0.0328],\n",
      "        [0.5576, 0.1267, 0.0992, 0.0026],\n",
      "        [0.4661, 0.4036, 0.1252, 0.1696]])\n",
      "Matmul t1 @ t2\n",
      "tensor([[0.5562, 1.7101, 1.3802],\n",
      "        [0.4147, 0.7861, 0.7040],\n",
      "        [0.5721, 1.5741, 1.1645]])\n"
     ]
    }
   ],
   "source": [
    "### multiplying two tensors\n",
    "print('Element wise multiplication t1*t2')\n",
    "print(t1*t2)\n",
    "\n",
    "\n",
    "### If you want to perform matrix multiplication please ensure that the shapes are correct \n",
    "\n",
    "print(\"Matmul t1 @ t2\")\n",
    "print(torch.matmul(t1,t2.T)) ## 3 x 4 @ 4 x 3 --> 3 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6054, 1.7673, 1.7317, 1.2100],\n",
      "        [1.7466, 1.1533, 1.1374, 1.0058],\n",
      "        [1.6464, 1.9646, 1.1740, 1.3705]])\n",
      "tensor([[1.2108, 1.5345, 1.4634, 0.4200],\n",
      "        [1.4931, 0.3066, 0.2747, 0.0116],\n",
      "        [1.2927, 1.9291, 0.3480, 0.7411]])\n"
     ]
    }
   ],
   "source": [
    "### Scalar operations\n",
    "\n",
    "print(t1+1)\n",
    "print(t1*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_bKeCpjzLNQ"
   },
   "source": [
    "#### Other useful operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XD0cbGhInpsl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor1  tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "Sum tensor([4., 4., 4.])\n",
      "mean tensor([1., 1., 1., 1.])\n",
      "Tensor 2 tensor([0.8856, 0.6233, 0.3415])\n",
      "argmax tensor(0)\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.ones(size=(3,4))\n",
    "\n",
    "print(\"Tensor1 \", t1)\n",
    "## sum \n",
    "\n",
    "t1_sum = torch.sum(t1, dim =1)\n",
    "print(\"Sum\", t1_sum)\n",
    "\n",
    "t1_mean = torch.mean(t1, dim = 0)\n",
    "print(\"mean\", t1_mean)\n",
    "\n",
    "t2 = torch.rand(3)\n",
    "print(\"Tensor 2\", t2)\n",
    "\n",
    "t2_argmax = torch.argmax(t2)\n",
    "print(\"argmax\", t2_argmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore more about pytorch tensors: https://www.youtube.com/watch?v=r7QDUPb2dCM"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Recitation_0C_Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
